import os
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware
import google.generativeai as genai
from dotenv import load_dotenv
import psycopg2
import rss_service
import scraper_service
import ai_analyst
import trend_service
import drive_service

# .env dosyasÄ±nÄ± yÃ¼kle
from pathlib import Path
env_path = Path(__file__).parent / '.env'
load_dotenv(dotenv_path=env_path)

app = FastAPI(title="Nomad API ðŸ¦…")

# CORS (Frontend'in Backend'e eriÅŸmesi iÃ§in)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Herkese aÃ§Ä±k (Credentials False olduÄŸu iÃ§in Ã§alÄ±ÅŸÄ±r)
    allow_credentials=False,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Gemini YapÄ±landÄ±rmasÄ±
API_KEY = os.getenv("GEMINI_API_KEY")
if not API_KEY:
    print("UYARI: GEMINI_API_KEY bulunamadÄ±!")
else:
    genai.configure(api_key=API_KEY)

# --- REQUEST MODELS ---
class SummarizeRequest(BaseModel):
    text: str

class QuestionRequest(BaseModel):
    question: str

class SaveRequest(BaseModel):
    text: str

class AnalysisRequest(BaseModel):
    title: str
    content: str
    
class NewFeedRequest(BaseModel):
    url: str
    category: str
    source_name: str

class ScanRequest(BaseModel):
    url: str

class ReportRequest(BaseModel):
    title: str
    content: str

# --- ENDPOINTS ---

@app.get("/")
def read_root():
    return {"status": "Nomad Backend (Cloud Native) is Running ðŸš€"}

@app.get("/admin/init-db")
def init_database_tables():
    """VeritabanÄ± TablolarÄ±nÄ± Cloud Ãœzerinden OluÅŸturur (Migration)"""
    conn = None
    try:
        conn = get_db_connection()
        cur = conn.cursor()
        
        # 1. FEEDS TABLE
        cur.execute("""
            CREATE TABLE IF NOT EXISTS feeds (
                id SERIAL PRIMARY KEY,
                url TEXT UNIQUE NOT NULL,
                categoryvb TEXT,
                source_name TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
        """)
        
        # 2. AGENT MEMORY TABLE
        cur.execute("""
            CREATE TABLE IF NOT EXISTS agent_memory (
                id SERIAL PRIMARY KEY,
                content TEXT,
                embedding TEXT, 
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
        """)
        
        conn.commit()
        cur.close()
        return {"status": "SUCCESS", "message": "Tables 'feeds' and 'agent_memory' ensure created."}
        
    except Exception as e:
        if conn: conn.rollback()
        return {"status": "FAILED", "error": str(e)}
    finally:
        if conn: conn.close()

@app.get("/debug-db")
def debug_database():
    """VeritabanÄ± baÄŸlantÄ±sÄ±nÄ± test eder ve deÄŸiÅŸkenleri kontrol eder"""
    import os
    db_pass = os.getenv("DB_PASSWORD", "")
    db_url = os.getenv("DB_URL", "")
    
    debug_info = {
        "DB_PASSWORD_LEN": len(db_pass) if db_pass else 0,
        "DB_PASSWORD_START": db_pass[:2] if db_pass else "NONE",
        "DB_PASSWORD_END": db_pass[-2:] if db_pass else "NONE",
        "DB_URL_PRESENT": bool(db_url),
        "HOST": os.getenv("DB_HOST"),
    }
    
    try:
        conn = get_db_connection()
        conn.close()
        return {"status": "CONNECTED", "debug": debug_info}
    except Exception as e:
        return {"status": "FAILED", "error": str(e), "debug": debug_info}

# RSS & AI Analysis Endpoints
@app.get("/feeds")
def get_feeds(category: str = "ALL"):
    """RSS akÄ±ÅŸlarÄ±nÄ± getirir"""
    return rss_service.fetch_feeds(category)

@app.get("/sources")
def get_feed_sources():
    """Admin: KayÄ±tlÄ± tÃ¼m RSS kaynaklarÄ±nÄ± listeler"""
    return rss_service.get_db_feeds(active_only=False)

@app.get("/trends")
async def get_global_trends():
    """Son haberlerden trend analizi yapar"""
    # 1. TÃ¼m haberleri Ã§ek
    all_news = rss_service.fetch_feeds("ALL")
    # 2. Trend servisine gÃ¶nder
    trends = trend_service.analyze_trends(all_news)
    return trends

@app.post("/feeds/add")
def add_new_feed(request: NewFeedRequest):
    """Yeni RSS kaynaÄŸÄ± ekler (GeliÅŸmiÅŸ - Duplicate Check)"""
    conn = None
    try:
        # 1. Ã–nce Linki DoÄŸrula
        # Bu iÅŸlem uzun sÃ¼rebilir, timeout yiyebilir, DB'den Ã¶nce yapÄ±lmasÄ± iyi.
        is_valid, msg = rss_service.verify_rss_url(request.url)
        if not is_valid:
            raise HTTPException(status_code=400, detail=f"RSS Error: {msg}")

        conn = get_db_connection()
        cur = conn.cursor()

        # 2. Bu link zaten var mÄ±?
        cur.execute("SELECT id FROM feeds WHERE url = %s", (request.url,))
        if cur.fetchone():
            raise HTTPException(status_code=400, detail="Bu kaynak zaten ekli Kaptan!")

        # 3. Yoksa ekle
        cur.execute(
            "INSERT INTO feeds (url, categoryvb, source_name) VALUES (%s, %s, %s) RETURNING id",
            (request.url, request.category.upper(), request.source_name.upper())
        )
        new_id = cur.fetchone()[0]
        conn.commit()
        return {"status": "success", "message": f"Feed added: {request.source_name}", "id": new_id}

    except HTTPException:
        if conn: conn.rollback()
        raise # Kendi fÄ±rlattÄ±ÄŸÄ±mÄ±z hatalarÄ± olduÄŸu gibi geÃ§
    except Exception as e:
        if conn: conn.rollback()
        print(f"CRITICAL ERROR in add_new_feed: {e}")
        # Hata detayÄ±nÄ± return et ki debug edebilelim
        raise HTTPException(status_code=500, detail=f"System Crash: {str(e)}")
    finally:
        if conn:
            conn.close()

@app.get("/categories")
def get_categories():
    """Mevcut kategorileri dinamik olarak listeler"""
    conn = get_db_connection()
    cur = conn.cursor()
    try:
        cur.execute("SELECT DISTINCT categoryvb FROM feeds")
        cats = [row[0] for row in cur.fetchall()]
        if "ALL" not in cats: cats.insert(0, "ALL")
        return cats
    except Exception as e:
        print(f"Cat Error: {e}")
        return ["ALL", "TECH", "CYBERSEC"] # Hata olursa varsayÄ±lanlarÄ± dÃ¶n
    finally:
        cur.close()
        conn.close()

@app.delete("/feeds/{feed_id}")
def delete_feed(feed_id: int):
    """Feed'i kalici olarak siler"""
    if rss_service.delete_feed_from_db(feed_id):
        return {"status": "success", "message": f"Feed {feed_id} deleted."}
    else:
        raise HTTPException(status_code=404, detail="Feed bulunamadÄ± veya silinemedi.")

@app.post("/analyze")
def analyze_news(request: AnalysisRequest):
    """SeÃ§ilen haberi AI'a gÃ¶nderir"""
    result = ai_analyst.analyze_article(request.title, request.content)
    return result

@app.post("/scan")
def deep_scan_url(request: ScanRequest):
    """Verilen URL'i tarar ve analiz eder"""
    scraped_data = scraper_service.scrape_url(request.url)
    
    if not scraped_data:
        raise HTTPException(status_code=400, detail="URL taranamadÄ± veya iÃ§erik alÄ±namadÄ±.")
        
    # AI Analizi
    analysis = ai_analyst.analyze_article(scraped_data['title'], scraped_data['content'])
    
    # Orijinal linki de analize ekle ki kaydederken kullanabilelim
    analysis['link'] = request.url
    
    return analysis

@app.get("/graph-data")
def get_graph_data():
    """Neural Graph iÃ§in veritabanÄ±ndan node ve linkleri Ã§eker"""
    conn = get_db_connection()
    cur = conn.cursor()
    try:
        # 1. HafÄ±zadaki tÃ¼m verileri Ã§ek (content ve embedding lazÄ±m deÄŸil, id ve content yeter)
        cur.execute("SELECT id, content FROM agent_memory ORDER BY created_at DESC LIMIT 50")
        rows = cur.fetchall()
        
        nodes = []
        links = []
        
        # Basit bir iliÅŸkilendirme (Tag veya anahtar kelimeye gÃ¶re)
        # GerÃ§ek bir sistemde embedding distance kullanÄ±labilir.
        # Åžimdilik: "TECH", "AI", "SPACE", "SECURITY" kelimelerini iÃ§erenleri birbirine baÄŸlayalÄ±m.
        
        keywords = ["AI", "DATA", "ROBOT", "SPACE", "SECURITY", "CYBER", "CODE", "SYSTEM", "FUTURE", "MODEL"]
        
        for r in rows:
            mem_id = r[0]
            text = r[1]
            title = text.split('|')[0][:30] + "..." if '|' in text else text[:30] + "..."
            
            # Node ekle
            nodes.append({
                "id": str(mem_id),
                "name": title,
                "group": "memory",
                "val": 5
            })
            
            # Link oluÅŸtur (Basit anahtar kelime eÅŸleÅŸmesi)
            found_keys = [k for k in keywords if k in text.upper()]
            # Her bir keyword iÃ§in sanal bir grup node'u oluÅŸturabiliriz veya birbirlerine baÄŸlayabiliriz.
            # Åžimdilik rastgele bir Ã¶nceki node'a baÄŸlayalÄ±m ki aÄŸ oluÅŸsun (Demo)
            import random
            if len(nodes) > 1 and random.random() > 0.5:
                target = nodes[random.randint(0, len(nodes)-2)]
                links.append({
                    "source": str(mem_id),
                    "target": target["id"]
                })
                
        # Merkez Node
        nodes.append({"id": "CORE", "name": "NOMAD CORE", "group": "core", "val": 15})
        for n in nodes[:5]: # Ä°lk 5'i merkeze baÄŸla
            if n["id"] != "CORE":
                links.append({"source": n["id"], "target": "CORE"})

        return {"nodes": nodes, "links": links}

    except Exception as e:
        print(f"Graph Error: {e}")
        return {"nodes": [], "links": []}
    finally:
        cur.close()
        conn.close()

@app.get("/stats")
def get_dashboard_stats():
    from collections import Counter
    import re
    conn = get_db_connection()
    cur = conn.cursor()
    try:
        # 1. Klasik SayaÃ§lar
        cur.execute("SELECT COUNT(*) FROM feeds")
        total_sources = cur.fetchone()[0]
        
        try:
            cur.execute("SELECT COUNT(*) FROM agent_memory")
            total_intel = cur.fetchone()[0]
        except:
            total_intel = 0

        # --- 2. SQL TABANLI TREND ANALÄ°ZÄ° (OPTIMIZED) ---
        # Son 100 haberin baÅŸlÄ±ÄŸÄ±nÄ± Ã§ek
        dominant_trend = "WAITING DATA..."
        try:
            cur.execute("SELECT content FROM agent_memory ORDER BY created_at DESC LIMIT 100")
            rows = cur.fetchall()
            
            if rows:
                all_text = " ".join([r[0] for r in rows]).lower()
                
                # Basit Kelime FrekansÄ±
                words = re.findall(r'\w+', all_text)
                ignored = {'the', 'and', 'for', 'with', 'summary', 'insight', 'tags', 'title', 'date', 'source', 'to', 'of', 'in', 'a', 'is', 'link', 'http', 'https', 'com', 'org', 'net', 'www', 'news', 'feed'}
                filtered_words = [w for w in words if w not in ignored and len(w) > 3]
                
                if filtered_words:
                    most_common = Counter(filtered_words).most_common(1)
                    dominant_trend = most_common[0][0].upper()
        except Exception as e:
            print(f"Trend Calc Error: {e}")

        # 3. Son Haberler
        recent_alerts = []
        try:
            cur.execute("SELECT content, created_at FROM agent_memory ORDER BY created_at DESC LIMIT 5")
            for r in cur.fetchall():
                parts = r[0].split('|')
                title = parts[0][:50] + "..." if len(parts) > 0 else "Signal"
                recent_alerts.append({"title": title, "time": str(r[1])})
        except:
            pass

        return {
            "total_sources": total_sources,
            "total_intel": total_intel,
            "top_trend": dominant_trend,
            "system_status": "OPTIMIZED",
            "recent_alerts": recent_alerts
        }
    except Exception as e:
        print(f"Stats Error: {e}")
        return {"total_sources": 0, "total_intel": 0, "top_trend": "OFFLINE", "system_status": "ERROR", "recent_alerts": []}
    finally:
        cur.close()
        conn.close()

# RAG & Memory Endpoints
@app.post("/summarize")
def summarize_text(request: SummarizeRequest):
    if not API_KEY:
        raise HTTPException(status_code=500, detail="API Key eksik.")
    
    try:
        # Try different model names in order of preference
        model_names = [
            "gemini-2.0-flash-exp", # Latest/Fastest
            "gemini-1.5-flash",
            "gemini-1.5-flash-latest",
            "gemini-pro"
        ]
        model = None
        
        last_error = None
        for name in model_names:
            try:
                model = genai.GenerativeModel(name)
                # Test generation call? No, usually unnecessary overhead, but good for validation.
                # Just break if initialization succeeded (which is lazy in this lib, so maybe redundant).
                # But let's proceed to generate with the first successful model.
                prompt = f"AÅŸaÄŸÄ±daki metni TÃ¼rkÃ§e olarak, maddeler halinde Ã¶zetle:\n\n{request.text}"
                response = model.generate_content(prompt)
                return {"summary": response.text}
            except Exception as e:
                # print(f"Model {name} failed: {e}")
                last_error = e
                continue
        
        if last_error:
            raise last_error
            
        return {"summary": "No model available."}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/ask")
def chat_with_memory(request: QuestionRequest):
    """
    Nomad'Ä±n hafÄ±zasÄ±yla konuÅŸmak iÃ§in endpoint.
    """
    from rag_service import ask_nomad
    answer = ask_nomad(request.question)
    return {"answer": answer}

@app.post("/save")
def save_to_memory(request: SaveRequest):
    # 1. Metnin VektÃ¶rÃ¼nÃ¼ Ãœret
    from embedding_service import generate_embedding
    vector = generate_embedding(request.text)
    
    if not vector:
        raise HTTPException(status_code=500, detail="VektÃ¶r Ã¼retilemedi.")
    
    try:
        # 2. VeritabanÄ±na Kaydet
        conn = get_db_connection()
        cursor = conn.cursor()
        
        insert_query = "INSERT INTO agent_memory (content, embedding) VALUES (%s, %s) RETURNING id;"
        cursor.execute(insert_query, (request.text, str(vector)))
        memory_id = cursor.fetchone()[0]
        
        conn.commit()
        cursor.close()
        conn.close()
        
        return {"status": "success", "id": memory_id, "message": "Bilgi Nomad'Ä±n hafÄ±zasÄ±na kazÄ±ndÄ±."}
        
    except Exception as e:
        print(f"DB Error: {e}")
        raise HTTPException(status_code=500, detail=f"VeritabanÄ± HatasÄ±: {str(e)}")

@app.post("/upload-report")
def upload_intelligence_report(request: ReportRequest):
    """
    Raporu Google Drive'a (Docs formatÄ±nda) yÃ¼kler.
    HTML iÃ§eriÄŸi alÄ±r, Drive API ile dÃ¶nÃ¼ÅŸtÃ¼rÃ¼p 'Nomad Intelligence' klasÃ¶rÃ¼ne atar.
    """
    result = drive_service.upload_html_as_doc(request.title, request.content)
    
    if result.get("status") == "error":
        raise HTTPException(status_code=500, detail=result.get("message"))
        
    return result

@app.get("/stats")
def get_dashboard_stats():
    conn = get_db_connection()
    cur = conn.cursor()
    try:
        # 1. Toplam Kaynak
        cur.execute("SELECT COUNT(*) FROM feeds")
        total_sources = cur.fetchone()[0]

        # 2. Ä°ÅŸlenen Veri
        try:
            cur.execute("SELECT COUNT(*) FROM agent_memory")
            total_intel = cur.fetchone()[0]
        except:
            total_intel = 0

        # 3. DOMINANT TREND (En Ã§ok hangi kategoriden haber var?)
        dominant_trend = "GENEL"
        try:
            cur.execute("""
                SELECT categoryvb, COUNT(*) as count 
                FROM feeds 
                GROUP BY categoryvb 
                ORDER BY count DESC 
                LIMIT 1
            """)
            row = cur.fetchone()
            if row:
                dominant_trend = row[0] # Ã–rn: AI, TECH, SCIENCE
        except:
            pass
        
        # 4. Son Kritik GeliÅŸmeler (YÃ¼ksek skorlu son haberler)
        recent_alerts = []
        try:
            # Sadece tehdit deÄŸil, skoru yÃ¼ksek (Ã¶nemli) haberleri Ã§ekelim
            cur.execute("SELECT content, created_at FROM agent_memory ORDER BY created_at DESC LIMIT 5")
            rows = cur.fetchall()
            for r in rows:
                parts = r[0].split('|')
                title = parts[0] if len(parts) > 0 else "Signal"
                recent_alerts.append({"title": title, "time": str(r[1])})
        except:
            pass

        return {
            "total_sources": total_sources,
            "total_intel": total_intel,
            "top_trend": dominant_trend,  # <-- YENÄ°: En popÃ¼ler konu
            "system_status": "ONLINE",
            "recent_alerts": recent_alerts
        }
    except Exception as e:
        print(f"Stats Error: {e}")
        return {"total_sources": 0, "total_intel": 0, "top_trend": "ANALYZING", "system_status": "OFFLINE", "recent_alerts": []}
    finally:
        cur.close()
        conn.close()

# VeritabanÄ± BaÄŸlantÄ±sÄ±
# VeritabanÄ± BaÄŸlantÄ±sÄ± - Robust
def get_db_connection():
    from urllib.parse import urlparse
    
    # 1. Direct Env Vars (Safest for special chars)
    db_pass = os.getenv("DB_PASSWORD")
    db_host = os.getenv("DB_HOST")
    db_user = os.getenv("DB_USER", "postgres")
    db_name = os.getenv("DB_NAME", "postgres")
    
    if db_pass and db_host:
        return psycopg2.connect(
            database=db_name,
            user=db_user,
            password=db_pass,
            host=db_host,
            port=5432,
            sslmode="require"
        )

    # 2. Fallback to URL Parsing
    db_url = os.getenv("DB_URL")
    if not db_url:
        return psycopg2.connect("postgresql://postgres:mypassword@localhost:5432/nomad?sslmode=disable")
        
    try:
        # Check if sslmode is explicitly disabled in the URL string
        ssl_mode = "require"
        if "sslmode=disable" in db_url:
            ssl_mode = "disable"

        result = urlparse(db_url)
        if result.username and result.password:
            return psycopg2.connect(
                database=result.path[1:] if result.path else "postgres",
                user=result.username,
                password=result.password,
                host=result.hostname,
                port=result.port,
                sslmode=ssl_mode
            )
        else:
            return psycopg2.connect(db_url)
    except Exception as e:
        print(f"Connection String Parsing Error: {e}")
        # Ensure fallback connects even if parsing fails
        return psycopg2.connect(db_url)

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8001)
