import os
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware
import google.generativeai as genai
from dotenv import load_dotenv
import psycopg2
import rss_service
import ai_analyst

# .env dosyasÄ±nÄ± yÃ¼kle
load_dotenv()

app = FastAPI(title="Nomad API ðŸ¦…")

# CORS (Frontend'in Backend'e eriÅŸmesi iÃ§in)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # GeliÅŸtirme aÅŸamasÄ±nda herkese aÃ§Ä±k
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Gemini YapÄ±landÄ±rmasÄ±
API_KEY = os.getenv("GEMINI_API_KEY")
if not API_KEY:
    print("UYARI: GEMINI_API_KEY bulunamadÄ±!")
else:
    genai.configure(api_key=API_KEY)

# --- REQUEST MODELS ---
class SummarizeRequest(BaseModel):
    text: str

class QuestionRequest(BaseModel):
    question: str

class SaveRequest(BaseModel):
    text: str

class AnalysisRequest(BaseModel):
    title: str
    content: str
    
class NewFeedRequest(BaseModel):
    url: str
    category: str
    source_name: str

# --- ENDPOINTS ---

@app.get("/")
def read_root():
    return {"status": "Nomad Backend (Cloud Native) is Running ðŸš€"}

# RSS & AI Analysis Endpoints
@app.get("/feeds")
def get_feeds(category: str = "ALL"):
    """RSS akÄ±ÅŸlarÄ±nÄ± getirir"""
    return rss_service.fetch_feeds(category)

@app.post("/feeds/add")
def add_new_feed(request: NewFeedRequest):
    """Yeni RSS kaynaÄŸÄ± ekler"""
    feed_id = rss_service.add_feed_to_db(request.url, request.category, request.source_name)
    if feed_id:
        return {"status": "success", "message": f"Feed added: {request.source_name}"}
    else:
        raise HTTPException(status_code=500, detail="Database error")

@app.get("/categories")
def get_categories():
    """Mevcut kategorileri listeler"""
    feeds = rss_service.get_db_feeds()
    categories = ["ALL"] + list(feeds.keys())
    return categories

@app.post("/analyze")
def analyze_news(request: AnalysisRequest):
    """SeÃ§ilen haberi AI'a gÃ¶nderir"""
    result = ai_analyst.analyze_article(request.title, request.content)
    return result

# RAG & Memory Endpoints
@app.post("/summarize")
def summarize_text(request: SummarizeRequest):
    if not API_KEY:
        raise HTTPException(status_code=500, detail="API Key eksik.")
    
    try:
        # En hÄ±zlÄ± ve ucuz model: Listeden bulunan gecerli model
        model = genai.GenerativeModel('models/gemini-2.5-flash')
        
        prompt = f"AÅŸaÄŸÄ±daki metni TÃ¼rkÃ§e olarak, maddeler halinde Ã¶zetle:\n\n{request.text}"
        response = model.generate_content(prompt)
        
        return {"summary": response.text}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/ask")
def chat_with_memory(request: QuestionRequest):
    """
    Nomad'Ä±n hafÄ±zasÄ±yla konuÅŸmak iÃ§in endpoint.
    """
    from rag_service import ask_nomad
    answer = ask_nomad(request.question)
    return {"answer": answer}

@app.post("/save")
def save_to_memory(request: SaveRequest):
    # 1. Metnin VektÃ¶rÃ¼nÃ¼ Ãœret
    from embedding_service import generate_embedding
    vector = generate_embedding(request.text)
    
    if not vector:
        raise HTTPException(status_code=500, detail="VektÃ¶r Ã¼retilemedi.")
    
    try:
        # 2. VeritabanÄ±na Kaydet
        conn = get_db_connection()
        cursor = conn.cursor()
        
        insert_query = "INSERT INTO agent_memory (content, embedding) VALUES (%s, %s) RETURNING id;"
        cursor.execute(insert_query, (request.text, str(vector)))
        memory_id = cursor.fetchone()[0]
        
        conn.commit()
        cursor.close()
        conn.close()
        
        return {"status": "success", "id": memory_id, "message": "Bilgi Nomad'Ä±n hafÄ±zasÄ±na kazÄ±ndÄ±."}
        
    except Exception as e:
        print(f"DB Error: {e}")
        raise HTTPException(status_code=500, detail=f"VeritabanÄ± HatasÄ±: {str(e)}")

@app.get("/graph-data")
def get_graph_data():
    """
    Obsidian benzeri Graph View iÃ§in veri oluÅŸturur.
    HafÄ±zadaki (agent_memory) verileri Ã§eker, ortak TAG'leri olanlarÄ± baÄŸlar.
    """
    nodes = []
    links = []
    
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        # Son 50 hafÄ±za kaydÄ±nÄ± Ã§ek (Performans iÃ§in limitli)
        cursor.execute("SELECT id, content FROM agent_memory ORDER BY id DESC LIMIT 50")
        rows = cursor.fetchall()
        
        # 1. DÃ¼ÄŸÃ¼mleri (Nodes) HazÄ±rla
        for row in rows:
            mem_id, content = row
            
            # Ä°Ã§erikten Tag'leri AyÄ±kla (Kaydederken Ã¶zel format kullanacaÄŸÄ±z)
            # Beklenen Format: "Title... | Tags: A, B, C | Insight..."
            extracted_tags = []
            label = f"Memory #{mem_id}"
            
            if "Tags:" in content:
                try:
                    # Basit string parsing ile veriyi ayÄ±klÄ±yoruz
                    parts = content.split("|")
                    
                    # BaÅŸlÄ±k (Ä°lk parÃ§a)
                    if len(parts) > 0:
                        label = parts[0].strip()[:20] + "..." 

                    # Tagler (Tags: ile baÅŸlayan parÃ§a)
                    tag_part = next((p for p in parts if "Tags:" in p), None)
                    if tag_part:
                        # Temizle: Tags: A, B, C -> ['A', 'B', 'C']
                        clean_tags = tag_part.replace("Tags:", "").strip()
                        extracted_tags = [t.strip() for t in clean_tags.split(",") if t.strip()]
                except:
                    pass

            nodes.append({
                "id": mem_id,
                "label": label,
                "full_content": content,
                "tags": extracted_tags,
                "val": 5 # DÃ¼ÄŸÃ¼m bÃ¼yÃ¼klÃ¼ÄŸÃ¼
            })

        # 2. BaÄŸlantÄ±larÄ± (Links) Kur
        # Ä°ki dÃ¼ÄŸÃ¼mÃ¼n ortak bir etiketi varsa aralarÄ±na Ã§izgi Ã§ek
        # Ancok Ã§ok genel tagler (TECH, AI vb.) tek baÅŸÄ±na baÄŸ kurmak iÃ§in yeterli deÄŸil.
        BROAD_TAGS = {"TECH", "AI", "SCIENCE", "DEV", "GENERAL"}
        
        for i in range(len(nodes)):
            for j in range(i + 1, len(nodes)):
                node_a = nodes[i]
                node_b = nodes[j]
                
                # KesiÅŸim kÃ¼mesi (Ortak tagler)
                common = set(node_a['tags']).intersection(set(node_b['tags']))
                
                # Sadece birden fazla ortak tag varsa VEYA tek ortak tag "Ã¶zel" (broad deÄŸil) ise baÄŸla
                if len(common) >= 2 or (len(common) == 1 and list(common)[0] not in BROAD_TAGS):
                    links.append({
                        "source": node_a['id'],
                        "target": node_b['id'],
                        "color": "#06b6d4" # Neon mavi baÄŸlantÄ±
                    })

        cursor.close()
        conn.close()
        
    except Exception as e:
        print(f"Graph Error: {e}")
    
    return {"nodes": nodes, "links": links}

# VeritabanÄ± BaÄŸlantÄ±sÄ±
def get_db_connection():
    conn_string = "postgresql://postgres:mypassword@localhost:5432/nomad?sslmode=disable"
    return psycopg2.connect(conn_string)

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8001)
